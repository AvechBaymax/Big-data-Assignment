# ğŸšŒ Bus GPS Lambda Architecture

Há»‡ thá»‘ng **Big Data Pipeline** xá»­ lÃ½ dá»¯ liá»‡u GPS xe buÃ½t theo kiáº¿n trÃºc **Lambda Architecture** vá»›i real-time streaming vÃ  batch processing.

![Architecture](https://img.shields.io/badge/Architecture-Lambda-blue)
![Kafka](https://img.shields.io/badge/Kafka-3.x-orange)
![Spark](https://img.shields.io/badge/Spark-3.5-yellow)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue)
![Grafana](https://img.shields.io/badge/Grafana-10.2-green)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED)

---

## ğŸ“Š Dataset

- **Nguá»“n dá»¯ liá»‡u**: GPS xe buÃ½t TP.HCM (~9.8 triá»‡u báº£n ghi/ngÃ y, 2,575 xe)
- **KÃ­ch thÆ°á»›c**: 849MB raw data
- **Thuá»™c tÃ­nh**:
  - `datetime` - Thá»i gian ghi nháº­n
  - `vehicle_id` - MÃ£ xe (biá»ƒn sá»‘)
  - `lng`, `lat` - Tá»a Ä‘á»™ GPS
  - `speed` - Tá»‘c Ä‘á»™ (km/h)
  - `driver` - MÃ£ tÃ i xáº¿
  - `door_up`, `door_down` - Tráº¡ng thÃ¡i cá»­a

---

## ğŸ—ï¸ Lambda Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           LAMBDA ARCHITECTURE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  CSV     â”‚     â”‚                   SPEED LAYER                       â”‚  â”‚
â”‚   â”‚  Data    â”‚â”€â”€â”€â”€â–¶â”‚  Kafka â”€â”€â–¶ Consumer â”€â”€â–¶ PostgreSQL â”€â”€â–¶ Grafana     â”‚  â”‚
â”‚   â”‚          â”‚     â”‚  (Real-time streaming, <1s latency)                 â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚                                                                     â”‚
â”‚        â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚        â”‚           â”‚                   BATCH LAYER                        â”‚  â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  HDFS â”€â”€â–¶ Spark â”€â”€â–¶ PostgreSQL                      â”‚  â”‚
â”‚                    â”‚  (Daily aggregations, analytics)                     â”‚  â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                    â”‚                  SERVING LAYER                       â”‚  â”‚
â”‚                    â”‚  PostgreSQL (Speed + Batch views)                    â”‚  â”‚
â”‚                    â”‚  Grafana Dashboard (Visualization)                   â”‚  â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ³ Tech Stack

| Component      | Technology   | Version | Port | Role                      |
| -------------- | ------------ | ------- | ---- | ------------------------- |
| Message Broker | Apache Kafka | 7.4.0   | 9092 | Real-time streaming       |
| Storage        | Hadoop HDFS  | 3.2.1   | 9870 | Distributed storage       |
| Processing     | Apache Spark | 3.5.0   | 8082 | Batch & Stream processing |
| Database       | PostgreSQL   | 15      | 5432 | Serving layer             |
| Visualization  | Grafana      | 10.2.0  | 3000 | Real-time dashboard       |
| DB Admin       | pgAdmin      | 4       | 5050 | Database management       |
| Coordination   | Zookeeper    | 7.4.0   | 2181 | Kafka coordination        |

---

## ğŸ“ Project Structure

```
first_project/
â”œâ”€â”€ docker-compose.yml          # Docker infrastructure
â”œâ”€â”€ hadoop.env                  # Hadoop configuration
â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ dashboards/
â”‚       â”‚   â””â”€â”€ bus_realtime.json       # Grafana dashboard
â”‚       â””â”€â”€ provisioning/
â”‚           â”œâ”€â”€ dashboards/dashboards.yml
â”‚           â””â”€â”€ datasources/datasources.yml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_2025-04-01.csv      # Full dataset (849MB)
â”‚   â””â”€â”€ samples/                # Test datasets
â”‚       â”œâ”€â”€ sample_quick_test.csv    (1,000 records)
â”‚       â”œâ”€â”€ sample_small_dev.csv     (10,000 records)
â”‚       â”œâ”€â”€ sample_medium_test.csv   (50,000 records)
â”‚       â””â”€â”€ sample_first_hour.csv    (100,000 records)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_db.sql             # PostgreSQL schema
â”‚   â”œâ”€â”€ create_sample_data.py   # Generate sample data
â”‚   â”œâ”€â”€ run_demo.ps1            # Windows demo script
â”‚   â””â”€â”€ run_demo.sh             # Linux demo script
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ kafka/
    â”‚   â”œâ”€â”€ producer.py         # CSV â†’ Kafka producer
    â”‚   â””â”€â”€ consumer.py         # Kafka â†’ Console consumer
    â”‚
    â”œâ”€â”€ streaming/
    â”‚   â””â”€â”€ speed_layer_consumer.py  # Kafka â†’ PostgreSQL (Speed Layer)
    â”‚
    â””â”€â”€ spark/
        â”œâ”€â”€ batch_layer.py      # HDFS â†’ PostgreSQL (Batch Layer)
        â””â”€â”€ batch_processing.py # Spark batch jobs
```

---

## ğŸš€ Quick Start

### 1. Prerequisites

- Docker Desktop
- Python 3.10+
- Git

### 2. Clone & Setup

```bash
git clone https://github.com/AvechBaymax/Big-data-Assignment.git
cd Big-data-Assignment
git checkout lambda_architectur
```

### 3. Start Infrastructure

```bash
# Start all services
docker-compose up -d

# Wait for services to be healthy (~60s)
docker ps

# Create Kafka topic
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic bus-gps-tracking \
  --partitions 3 \
  --replication-factor 1

# Initialize PostgreSQL database
docker exec postgres psql -U admin -d postgres -c "CREATE DATABASE bus_analytics;"
cat scripts/init_db.sql | docker exec -i postgres psql -U admin -d bus_analytics
```

### 4. Install Python Dependencies

```bash
pip install confluent-kafka psycopg2-binary pyspark
```

### 5. Run the Pipeline

**Terminal 1 - Start Speed Layer Consumer:**

```bash
python src/streaming/speed_layer_consumer.py
```

**Terminal 2 - Send Data via Producer:**

```bash
# Quick test (1000 records)
python src/kafka/producer.py data/samples/sample_quick_test.csv 1000

# Medium test (50000 records)
python src/kafka/producer.py data/samples/sample_medium_test.csv 50000

# Full data
python src/kafka/producer.py data/raw_2025-04-01.csv
```

### 6. View Dashboard

Open Grafana: http://localhost:3000

- **Username**: admin
- **Password**: admin123
- Navigate to: **Dashboards â†’ Bus GPS â†’ Bus GPS Real-time Dashboard**

---

## ğŸ“Š Dashboard Features

| Panel                   | Description                             |
| ----------------------- | --------------------------------------- |
| Active Buses            | Count of buses active in last 5 minutes |
| Avg Speed (km/h)        | Average speed of all buses              |
| Events (Last Hour)      | Total GPS events in the last hour       |
| Door Events (1h)        | Door open/close events                  |
| Real-time Bus Locations | Geo-map showing bus positions           |
| Speed Over Time         | Time-series chart of speed              |

---

## ğŸ—„ï¸ Database Schema

### Speed Layer Tables (Real-time)

```sql
-- Current bus locations (latest position per vehicle)
bus_realtime_location (
    vehicle_id, latitude, longitude, speed,
    driver_id, door_up, door_down, last_updated
)

-- Streaming history (last 24 hours)
bus_tracking_stream (
    id, vehicle_id, latitude, longitude, speed,
    driver_id, door_up, door_down, event_time, ingested_at
)
```

### Batch Layer Tables (Analytics)

```sql
-- Daily vehicle summary
daily_vehicle_summary (
    summary_date, vehicle_id, total_records, total_distance_km,
    avg_speed, max_speed, active_hours, door_events
)

-- Hourly traffic analysis
hourly_traffic_analysis (
    analysis_date, hour_of_day, active_vehicles,
    total_events, avg_speed, speed_variance
)

-- Driver performance
driver_performance (
    report_date, driver_id, vehicles_driven, total_events,
    avg_speed, max_speed, total_door_events
)

-- Geographic hotspots
geo_hotspots (
    analysis_date, lat_bucket, lng_bucket, event_count,
    unique_vehicles, avg_speed
)
```

---

## ğŸ”§ Service URLs

| Service       | URL                   | Credentials             |
| ------------- | --------------------- | ----------------------- |
| Grafana       | http://localhost:3000 | admin / admin123        |
| pgAdmin       | http://localhost:5050 | admin@admin.com / admin |
| Spark Master  | http://localhost:8082 | -                       |
| HDFS Namenode | http://localhost:9870 | -                       |
| Kafka         | localhost:9092        | -                       |

---

## ğŸ§ª Testing

### Test Kafka Connection

```bash
# List topics
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Consume messages
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic bus-gps-tracking \
  --from-beginning --max-messages 5
```

### Test PostgreSQL

```bash
# Check tables
docker exec postgres psql -U admin -d bus_analytics -c "\dt"

# Query real-time data
docker exec postgres psql -U admin -d bus_analytics -c \
  "SELECT COUNT(*) FROM bus_realtime_location;"
```

---

## ğŸ“ˆ Performance

| Metric              | Value           |
| ------------------- | --------------- |
| Producer Throughput | ~5,000 msgs/sec |
| Consumer Latency    | <1 second       |
| Kafka Partitions    | 3               |
| Compression         | LZ4             |
| Batch Insert Size   | 100 records     |

---

## ğŸ›‘ Stopping Services

```bash
# Stop all services
docker-compose down

# Stop and remove volumes (clean reset)
docker-compose down -v
```

---

## ğŸ‘¥ Authors

- **Team**: Big Data Assignment - HCMUT

---

## ğŸ“ License

MIT License
